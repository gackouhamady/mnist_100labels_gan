Voici une version **exceptionnelle** et **fidÃ¨le** de votre projet, prÃ©sentÃ©e sous forme de fichier Markdown (`README.md` ou `Main.md`) parfaitement structurÃ©e pour votre dÃ©pÃ´t. Elle intÃ¨gre vos noms, votre programme de Master Ã  l'UniversitÃ© Paris CitÃ©, ainsi que le plan dÃ©taillÃ© du rapport final.

---

# # Semi-Supervised GAN for MNIST (100 Labels)

<p align="center">
<img alt="University Paris CitÃ©" src="https://img.shields.io/badge/University-Paris%20CitÃ©-6f42c1?style=for-the-badge&logo=academia&logoColor=white">
<img alt="Master ML for Data Science" src="https://img.shields.io/badge/Master-Machine%20Learning%20for%20Data%20Science-1976D2?style=for-the-badge&logo=python&logoColor=white">
<img alt="Deep Learning Project" src="https://img.shields.io/badge/Project-Deep%20Learning%20-%20Semi--Supervised%20GAN-FF9800?style=for-the-badge&logo=jupyter&logoColor=white">
<img alt="Academic Year" src="https://img.shields.io/badge/Year-2025%2F2026-009688?style=for-the-badge&logo=googlecalendar&logoColor=white">
</p>

---

## ğŸ‘¨â€ğŸ”¬ Ã‰quipe Projet

**UniversitÃ© Paris CitÃ© â€” Master 2 Machine Learning for Data Science**

* **Manel LOUNISSI** ([manel2.lounissi@gmail.com](mailto:manel2.lounissi@gmail.com))
* **Sandeep-Singh NIRMAL** ([nirmalsinghsandeep@gmail.com](mailto:nirmalsinghsandeep@gmail.com))
* **Brice SAILLARD** ([brice.saillard.bs@gmail.com](mailto:brice.saillard.bs@gmail.com))
* **Hamady GACKOU** ([hamady.gackou@etu.u-paris.fr](mailto:hamady.gackou@etu.u-paris.fr))

**Superviseur :** Blaise Hanczar

---

## ğŸ¯ RÃ©sumÃ© du Projet

Ce projet explore la puissance de l'apprentissage **semi-supervisÃ©** Ã  l'aide de rÃ©seaux antagonistes gÃ©nÃ©ratifs (GAN). Dans un scÃ©nario oÃ¹ seulement **100 images Ã©tiquetÃ©es** (10 par classe) sont disponibles sur les 60 000 du dataset MNIST, nous dÃ©montrons comment un **Semi-Supervised GAN (SGAN)** peut surpasser drastiquement un CNN classique.

### La Solution : Discriminateur 

Le cÅ“ur de notre approche rÃ©side dans la modification du discriminateur pour qu'il ne se contente pas de distinguer le "vrai" du "faux", mais qu'il agisse comme un classificateur Ã  11 classes :

* **Classes 0-9 :** Chiffres manuscrits rÃ©els.
* **Classe 10 :** Images gÃ©nÃ©rÃ©es ("Fake").

---

## ğŸ“Š Performances Comparatives

| ModÃ¨le | DonnÃ©es Ã‰tiquetÃ©es | DonnÃ©es Non-Ã‰tiquetÃ©es | PrÃ©cision Test (%) |
| --- | --- | --- | --- |
| **Baseline CNN** | 100 | Non | 82.73% |
| **SGAN (K+1 + Feature Matching)** | 100 | **59,900** | **97.82%** |

---

## ğŸ›  Structure du Code & Pipeline

```bash
mnist_100labels_gan/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ cnn_baseline.py       # Architecture du modÃ¨le tÃ©moin
â”‚   â”œâ”€â”€ gan_generator.py      # GÃ©nÃ©rateur DCGAN-style
â”‚   â””â”€â”€ gan_discriminator.py  # Discriminateur (K+1 logits)
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_baseline.py     # Script d'entraÃ®nement supervisÃ©
â”‚   â””â”€â”€ train_semisup_gan.py  # Logique SGAN + Feature Matching
â”œâ”€â”€ report/
â”‚   â””â”€â”€ report_neurips.pdf    # Rapport scientifique final
â””â”€â”€ main.py                   # Point d'entrÃ©e unique

```

---

## ğŸ“ Plan de Rapport (Structure Scientifique)

Voici le plan rigoureux adoptÃ© pour la rÃ©daction de notre article (format NeurIPS) :

1. **Introduction**
* ProblÃ©matique du coÃ»t de l'Ã©tiquetage.
* Motivation pour l'utilisation des GANs en semi-supervisÃ©.


2. **Ã‰tat de l'art & Baseline**
* Description du CNN supervisÃ©.
* Analyse du sur-apprentissage (overfitting) en rÃ©gime de faibles donnÃ©es.


3. **MÃ©thodologie SGAN**
* Architecture du classificateur .
* Formulation des fonctions de perte (Supervised vs Unsupervised).
* **Feature Matching :** Technique de stabilisation de l'entraÃ®nement du GÃ©nÃ©rateur.


4. **DÃ©tails d'ImplÃ©mentation**
* HyperparamÃ¨tres (Adam, learning rates, batch sizes).
* Gestion du dataset MNIST (Split 100/59,900).


5. **RÃ©sultats ExpÃ©rimentaux**
* Courbes de convergence et d'accuracy.
* Visualisation des images gÃ©nÃ©rÃ©es par le SGAN.


6. **Discussion & Analyse**
* Pourquoi le SGAN gÃ©nÃ©ralise-t-il mieux ?
* RÃ´le de l'information structurelle des donnÃ©es non-Ã©tiquetÃ©es.


7. **Conclusion & Perspectives**
* ExtensibilitÃ© Ã  des datasets plus complexes (CIFAR-10).


8. **RÃ©fÃ©rences & Annexes**

---

## ğŸš€ Comment Reproduire

1. Cloner le dÃ©pÃ´t.
2. Installer les dÃ©pendances : `pip install -r requirements.txt`.
3. Lancer l'entraÃ®nement complet :
```bash
python main.py --mode all --labels 100

```


4. Consulter les rÃ©sultats dans `/experiments/results.json`.

---

<p align="center"><i>RÃ©alisÃ© avec rigueur et passion par l'Ã©quipe Gackou-Lounissi-Nirmal-Saillard.</i></p>

---

Souhaitez-vous que je dÃ©veloppe davantage une section spÃ©cifique du rapport (par exemple, la dÃ©monstration mathÃ©matique de la perte du discriminateur) ?
